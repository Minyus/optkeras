{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptKeras_Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adlTq181lzrT",
        "colab_type": "text"
      },
      "source": [
        "This notebook demonstrates how to use OptKeras, a Python package to optimize hyperparameters of Keras Deep Learning Models using Optuna.\n",
        "\n",
        "Please see the GitHub repository of OptKeras for details:\n",
        "https://github.com/Minyus/optkeras\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U087RvP2l0ew",
        "colab_type": "text"
      },
      "source": [
        "##  Set up Google Colab environment\n",
        "\n",
        "To run in Google Colab, specify a directory in Google Drive. (GPU is recommended.)\n",
        "\n",
        "To run in an environment other than Google Colab, just skip this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4WCNh4ZGn65",
        "colab_type": "code",
        "outputId": "0acf5839-b6d7-4a3d-f768-46b54552a16c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        }
      },
      "source": [
        "\"\"\" To use Google Drive with Colab, \n",
        "1. set use_google_drive to True, and\n",
        "2. specify a directory in Google Drive (Modify as in your Google Drive)\n",
        "(You will need to authorize manually.)\n",
        "\"\"\"\n",
        "use_google_drive = False\n",
        "workdir = '/content/drive/My Drive/Colab Notebooks/OptKeras_Example_Output'\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "try:\n",
        "    if use_google_drive:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        # Create target directory & all intermediate directories if don't exists\n",
        "        if not os.path.exists(workdir):\n",
        "            os.makedirs(workdir)\n",
        "            print('## Directory: ' , workdir ,  ' was created.') \n",
        "        os.chdir(workdir)\n",
        "        print('## Current working directory: ', os.getcwd())\n",
        "except:\n",
        "    print('Run the code without using Google Drive.')\n",
        "        \n",
        "try:    \n",
        "    print('## Check the uptime. (Google Colab reboots every 12 hours)')\n",
        "    !cat /proc/uptime | awk '{print \"Uptime is \" $1 /60 /60 \" hours (\" $1 \" sec)\"}'\n",
        "    print('## Check the GPU info')\n",
        "    !nvidia-smi\n",
        "    print('## Check the OS') \n",
        "    !cat /etc/issue\n",
        "    print('## Check the Python version') \n",
        "    !python --version\n",
        "    print('## Check the memory')\n",
        "    !free -h\n",
        "    print('## Check the disk')\n",
        "    !df -h\n",
        "except:\n",
        "    print('Run the code assuming the environment is not Google Colab.')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## Check the uptime. (Google Colab reboots every 12 hours)\n",
            "Uptime is 0.0274333 hours (98.76 sec)\n",
            "## Check the GPU info\n",
            "Fri May 10 04:11:49 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.56       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    17W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "## Check the OS\n",
            "Ubuntu 18.04.2 LTS \\n \\l\n",
            "\n",
            "## Check the Python version\n",
            "Python 3.6.7\n",
            "## Check the memory\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        418M         10G        908K        1.7G         12G\n",
            "Swap:            0B          0B          0B\n",
            "## Check the disk\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         359G   24G  317G   7% /\n",
            "tmpfs           6.4G     0  6.4G   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "tmpfs           6.4G   12K  6.4G   1% /var/colab\n",
            "/dev/sda1       365G   29G  337G   8% /opt/bin\n",
            "shm             6.0G     0  6.0G   0% /dev/shm\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it4-DX10mqlB",
        "colab_type": "text"
      },
      "source": [
        "## Install Optuna 0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeNktIMgWNOg",
        "colab_type": "code",
        "outputId": "01d7a74e-68eb-4431-83e4-1cad0664b56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 970
        }
      },
      "source": [
        "!pip install optuna==0.10.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna==0.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/4c/04fd099ffa103603fa778a8582ba514efb1f5457af66b9470f6974a14356/optuna-0.10.0.tar.gz (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (1.16.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (1.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (1.12.0)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (3.6.6)\n",
            "Collecting cliff (from optuna==0.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/d5/e811665fde537964dd355c6ce38bd1308ef0ebe966fb81b3f2c6810c3845/cliff-2.14.1-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.1MB/s \n",
            "\u001b[?25hCollecting colorlog (from optuna==0.10.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/68/4d/892728b0c14547224f0ac40884e722a3d00cb54e7a146aea0b3186806c9e/colorlog-4.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from optuna==0.10.0) (0.24.2)\n",
            "Collecting alembic (from optuna==0.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/8b/fa3bd058cccd5e9177fea4efa26bfb769228fdd3178436ad5e05830ef6ef/alembic-1.0.10.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 25.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==0.10.0) (0.7.2)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==0.10.0) (5.2.0)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==0.10.0) (3.13)\n",
            "Collecting cmd2!=0.8.3; python_version >= \"3.0\" (from cliff->optuna==0.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/7c/fc946c24dfe4b12ffdcd099216471c413bbcf48f94f86b91b4ea44ccbaa6/cmd2-0.9.12-py3-none-any.whl (92kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 35.5MB/s \n",
            "\u001b[?25hCollecting stevedore>=1.20.0 (from cliff->optuna==0.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/dc/6ee92bccfe3c0448786b30b693e6060d62ec8c4a3ec9a287bac1c1a8d8c9/stevedore-1.30.1-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 29.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna==0.10.0) (2.4.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->optuna==0.10.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->optuna==0.10.0) (2.5.3)\n",
            "Collecting Mako (from alembic->optuna==0.10.0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/bb/f4e5c056e883915c37bb5fb6fab7f00a923c395674f83bfb45c9ecf836b6/Mako-1.0.9.tar.gz (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 64.6MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3 (from alembic->optuna==0.10.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna==0.10.0) (19.1.0)\n",
            "Collecting colorama (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna==0.10.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna==0.10.0) (0.1.7)\n",
            "Collecting pyperclip>=1.5.27 (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna==0.10.0)\n",
            "  Downloading https://files.pythonhosted.org/packages/2d/0f/4eda562dffd085945d57c2d9a5da745cfb5228c02bc90f2c74bbac746243/pyperclip-1.7.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna==0.10.0) (1.1.1)\n",
            "Building wheels for collected packages: optuna, alembic, Mako, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a7/05/1ecde925de6085f0c79a1dfdfed50f5a6ecd60c0d55a389890\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/cf/b3/0eb5c89ea6aa1b49cb41315f9ec139ada8cbffd575bf170d43\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/23/48/366f0d8b14d436e58ad0aef531b14af8d8beabeb2986704bd5\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/f0/ac/2ba2972034e98971c3654ece337ac61e546bdeb34ca960dc8c\n",
            "Successfully built optuna alembic Mako pyperclip\n",
            "Installing collected packages: colorama, pyperclip, cmd2, stevedore, cliff, colorlog, Mako, python-editor, alembic, optuna\n",
            "Successfully installed Mako-1.0.9 alembic-1.0.10 cliff-2.14.1 cmd2-0.9.12 colorama-0.4.1 colorlog-4.0.2 optuna-0.10.0 pyperclip-1.7.0 python-editor-1.0.4 stevedore-1.30.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COmhC_CuoYo9",
        "colab_type": "text"
      },
      "source": [
        "## Install OptKeras 0.0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfIoE_CLvytu",
        "colab_type": "code",
        "outputId": "4c6e9727-e665-420a-a77c-162bc9417e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "#!pip install optkeras==0.0.4\n",
        "# Alternatively you can install from the GitHub repository\n",
        "!pip install git+https://github.com/Minyus/optkeras.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/Minyus/optkeras.git\n",
            "  Cloning https://github.com/Minyus/optkeras.git to /tmp/pip-req-build-bg94t371\n",
            "  Running command git clone -q https://github.com/Minyus/optkeras.git /tmp/pip-req-build-bg94t371\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from optkeras==0.0.4) (2.2.4)\n",
            "Requirement already satisfied: optuna>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from optkeras==0.0.4) (0.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optkeras==0.0.4) (1.16.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (1.0.7)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (1.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->optkeras==0.0.4) (1.0.9)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (1.0.10)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (1.3.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (0.24.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (4.0.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (3.6.6)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.6/dist-packages (from optuna>=0.9.0->optkeras==0.0.4) (2.14.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna>=0.9.0->optkeras==0.0.4) (2.5.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.6/dist-packages (from alembic->optuna>=0.9.0->optkeras==0.0.4) (1.0.9)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.6/dist-packages (from alembic->optuna>=0.9.0->optkeras==0.0.4) (1.0.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->optuna>=0.9.0->optkeras==0.0.4) (2018.9)\n",
            "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna>=0.9.0->optkeras==0.0.4) (0.7.2)\n",
            "Requirement already satisfied: stevedore>=1.20.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna>=0.9.0->optkeras==0.0.4) (1.30.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna>=0.9.0->optkeras==0.0.4) (2.4.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna>=0.9.0->optkeras==0.0.4) (5.2.0)\n",
            "Requirement already satisfied: cmd2!=0.8.3; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from cliff->optuna>=0.9.0->optkeras==0.0.4) (0.9.12)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna>=0.9.0->optkeras==0.0.4) (1.1.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna>=0.9.0->optkeras==0.0.4) (0.4.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna>=0.9.0->optkeras==0.0.4) (19.1.0)\n",
            "Requirement already satisfied: pyperclip>=1.5.27 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna>=0.9.0->optkeras==0.0.4) (1.7.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna>=0.9.0->optkeras==0.0.4) (0.1.7)\n",
            "Building wheels for collected packages: optkeras\n",
            "  Building wheel for optkeras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a17y4c6s/wheels/ad/c8/9d/67471f9fd7c5fd15961a2e7aa3d15215212d0631ea96df8b5c\n",
            "Successfully built optkeras\n",
            "Installing collected packages: optkeras\n",
            "Successfully installed optkeras-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nikvt-fppC8",
        "colab_type": "text"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i85DbXl0nvmU",
        "colab_type": "code",
        "outputId": "bbd550ae-67a4-47e0-d664-05ac4880a500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Dense, Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adagrad, RMSprop, Adam, Adadelta, Adamax, Nadam\n",
        "import keras.backend as K\n",
        "\n",
        "import keras\n",
        "print('Keras', keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "\n",
        "# import Optuna and OptKeras after Keras\n",
        "import optuna \n",
        "print('Optuna', optuna.__version__)\n",
        "\n",
        "from optkeras.optkeras import OptKeras\n",
        "import optkeras\n",
        "print('OptKeras', optkeras.__version__)\n",
        "\n",
        "# (Optional) Disable messages from Optuna below WARN level.\n",
        "optuna.logging.set_verbosity(optuna.logging.WARN) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Keras 2.2.4\n",
            "TensorFlow 1.13.1\n",
            "Optuna 0.10.0\n",
            "OptKeras 0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq16j0E4olJO",
        "colab_type": "text"
      },
      "source": [
        "## Set up Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfMZGHCO4DrV",
        "colab_type": "code",
        "outputId": "8cb791df-6ee9-4174-85aa-f6ccdb527150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "dataset_name = 'MNIST'\n",
        "\n",
        "if dataset_name in ['MNIST']:\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    img_x, img_y = x_train.shape[1], x_train.shape[2]\n",
        "    x_train = x_train.reshape(-1, img_x, img_y, 1)\n",
        "    x_test = x_test.reshape(-1, img_x, img_y, 1)   \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    num_classes = 10\n",
        "    input_shape = (img_x, img_y, 1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6QEQ_Dk6ReL",
        "colab_type": "code",
        "outputId": "293b30b0-3b84-4995-920f-80d31c83f1d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "print('x_train: ', x_train.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('x_test: ', x_test.shape)\n",
        "print('y_test', y_test.shape)\n",
        "print('input_shape: ', input_shape )    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train:  (60000, 28, 28, 1)\n",
            "y_train (60000,)\n",
            "x_test:  (10000, 28, 28, 1)\n",
            "y_test (10000,)\n",
            "input_shape:  (28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Wb1ZX2vJDO1",
        "colab_type": "text"
      },
      "source": [
        "## A simple Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5NqIOlKJBpO",
        "colab_type": "code",
        "outputId": "255f84d1-91d1-4143-d833-c208fefabeb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(\n",
        "    filters=32,\n",
        "    kernel_size=3,\n",
        "    strides=1,\n",
        "    activation='relu',\n",
        "    input_shape=input_shape ))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(optimizer=Adam(),\n",
        "            loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_test, y_test), shuffle=True,\n",
        "          batch_size=512, epochs=2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.4450 - acc: 0.8813 - val_loss: 0.2097 - val_acc: 0.9396\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 1s 17us/step - loss: 0.1632 - acc: 0.9552 - val_loss: 0.1227 - val_acc: 0.9664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a95bc8828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_MtiEV0kcSd",
        "colab_type": "text"
      },
      "source": [
        "## Optimization of a simple Keras model without pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpr1zgHub1QN",
        "colab_type": "code",
        "outputId": "f975a800-735c-49a6-c3ed-4da1fc0aa69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1269
        }
      },
      "source": [
        "study_name = dataset_name + '_Simple'\n",
        "\n",
        "\"\"\" Step 1. Instantiate OptKeras class\n",
        "You can specify arguments for Optuna's create_study method and other arguments \n",
        "for OptKeras such as enable_pruning. \n",
        "\"\"\"\n",
        "\n",
        "ok = OptKeras(study_name=study_name,\n",
        "              monitor='val_acc',\n",
        "              direction='maximize')\n",
        "\n",
        "\n",
        "\"\"\" Step 2. Define objective function for Optuna \"\"\"\n",
        "\n",
        "def objective(trial):\n",
        "    \n",
        "    \"\"\" Clear the backend (TensorFlow). See:\n",
        "    https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session\n",
        "    \"\"\"\n",
        "    K.clear_session() \n",
        "    \n",
        "    \"\"\" Step 2.1. Define parameters to try using methods of optuna.trial such as \n",
        "    suggest_categorical. In this simple demo, try 2*2*2*2 = 16 parameter sets: \n",
        "    2 values specified in list for each of 4 parameters \n",
        "    (filters, kernel_size, strides, and activation for convolution).\n",
        "    \"\"\"    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(\n",
        "        filters=trial.suggest_categorical('filters', [32, 64]),\n",
        "        kernel_size=trial.suggest_categorical('kernel_size', [3, 5]),\n",
        "        strides=trial.suggest_categorical('strides', [1, 2]),\n",
        "        activation=trial.suggest_categorical('activation', ['relu', 'linear']),\n",
        "        input_shape=input_shape ))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(),\n",
        "                loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    \"\"\" Step 2.2. Specify callbacks(trial) and keras_verbose in fit \n",
        "    (or fit_generator) method of Keras model\n",
        "    \"\"\"\n",
        "    model.fit(x_train, y_train, \n",
        "              validation_data=(x_test, y_test), shuffle=True,\n",
        "              batch_size=512, epochs=2,\n",
        "              callbacks=ok.callbacks(trial),\n",
        "              verbose=ok.keras_verbose )\n",
        "    \n",
        "    \"\"\" Step 2.3. Return trial_best_value (or latest_value) \"\"\"\n",
        "    return ok.trial_best_value\n",
        "\n",
        "\"\"\" Step 3. Run optimize. \n",
        "Set n_trials and/or timeout (in sec) for optimization by Optuna\n",
        "\"\"\"\n",
        "ok.optimize(objective, timeout = 3*60) # Run for 3 minutes for demo\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-05-10 04:12:32.329143] [OptKeras] Ready for optimization. (message printed as verbose is set to 1+)\n",
            "[2019-05-10 04:12:32.617957]  (None) \n",
            "[2019-05-10 04:12:34.823713] Trial#: 0, value: 9.734000e-01| Best trial#: 0, value: 9.734000e-01, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:36.822416] Trial#: 1, value: 9.191000e-01| Best trial#: 0, value: 9.734000e-01, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:38.516447] Trial#: 2, value: 9.329000e-01| Best trial#: 0, value: 9.734000e-01, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:40.622794] Trial#: 3, value: 9.233000e-01| Best trial#: 0, value: 9.734000e-01, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:42.834727] Trial#: 4, value: 9.699000e-01| Best trial#: 0, value: 9.734000e-01, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:45.965986] Trial#: 5, value: 9.791000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:49.036116] Trial#: 6, value: 9.777000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:50.637220] Trial#: 7, value: 9.147000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:52.369866] Trial#: 8, value: 9.538000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:54.205784] Trial#: 9, value: 9.534000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:12:57.845621] Trial#: 10, value: 9.687000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:00.635603] Trial#: 11, value: 9.211000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:04.093473] Trial#: 12, value: 9.721000e-01| Best trial#: 5, value: 9.791000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:07.198648] Trial#: 13, value: 9.808000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:10.282440] Trial#: 14, value: 9.775000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:12.076781] Trial#: 15, value: 9.197000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:15.187235] Trial#: 16, value: 9.803000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:18.283091] Trial#: 17, value: 9.773000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:21.382059] Trial#: 18, value: 9.786000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:24.467215] Trial#: 19, value: 9.781000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:27.566394] Trial#: 20, value: 9.801000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:30.666055] Trial#: 21, value: 9.787000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:33.770593] Trial#: 22, value: 9.786000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:36.868323] Trial#: 23, value: 9.791000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:40.293564] Trial#: 24, value: 9.709000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:42.036434] Trial#: 25, value: 9.198000e-01| Best trial#: 13, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:45.142178] Trial#: 26, value: 9.808000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:48.245547] Trial#: 27, value: 9.792000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:51.358945] Trial#: 28, value: 9.778000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:53.159069] Trial#: 29, value: 9.205000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:56.267490] Trial#: 30, value: 9.782000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:13:58.506298] Trial#: 31, value: 9.762000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:01.449809] Trial#: 32, value: 9.190000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:03.142186] Trial#: 33, value: 9.485000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:06.249020] Trial#: 34, value: 9.793000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:08.402845] Trial#: 35, value: 9.160000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:11.519274] Trial#: 36, value: 9.802000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:13.300421] Trial#: 37, value: 9.521000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:16.148966] Trial#: 38, value: 9.211000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:18.635532] Trial#: 39, value: 9.735000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:20.792868] Trial#: 40, value: 9.437000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:24.127912] Trial#: 41, value: 9.783000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:26.386713] Trial#: 42, value: 9.191000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:28.336759] Trial#: 43, value: 9.465000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:31.471121] Trial#: 44, value: 9.769000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:34.598037] Trial#: 45, value: 9.779000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:36.638963] Trial#: 46, value: 9.210000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:38.588167] Trial#: 47, value: 9.423000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:41.711349] Trial#: 48, value: 9.795000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:44.840798] Trial#: 49, value: 9.800000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:47.111040] Trial#: 50, value: 9.751000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:48.857040] Trial#: 51, value: 9.175000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:52.312235] Trial#: 52, value: 9.694000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:55.469176] Trial#: 53, value: 9.794000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:14:58.598826] Trial#: 54, value: 9.763000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:01.313398] Trial#: 55, value: 9.204000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:03.084084] Trial#: 56, value: 9.312000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:06.230346] Trial#: 57, value: 9.776000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:09.368367] Trial#: 58, value: 9.802000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:12.519707] Trial#: 59, value: 9.783000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:14.347649] Trial#: 60, value: 9.173000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:16.638682] Trial#: 61, value: 9.749000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:19.775140] Trial#: 62, value: 9.780000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:22.917685] Trial#: 63, value: 9.790000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:24.750899] Trial#: 64, value: 9.174000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:27.888886] Trial#: 65, value: 9.771000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:31.034187] Trial#: 66, value: 9.778000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:15:34.165843] Trial#: 67, value: 9.781000e-01| Best trial#: 26, value: 9.808000e-01, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5SKUF9qXlp",
        "colab_type": "code",
        "outputId": "408b3b39-b5c0-48d3-a514-54e47c2639db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1147
        }
      },
      "source": [
        "\"\"\" Show Results \"\"\"\n",
        "print('Best trial number: ', ok.best_trial.number)\n",
        "print('Best value:', ok.best_trial.value)\n",
        "print('Best parameters: \\n', ok.best_trial.params)\n",
        "\n",
        "\"\"\"\n",
        "Alternatively, you can access Optuna's study object to, for example, \n",
        "get the best parameters as well.\n",
        "Please note that study.best_trial returns error if optimization trials \n",
        "were not completed (e.g. if you interrupt execution) as of Optuna 0.7.0, \n",
        "so usage of OptKeras is recommended.\n",
        "\"\"\"\n",
        "print(\"Best parameters (retrieved directly from Optuna)\", ok.study.best_trial.params)\n",
        "\n",
        "\"\"\" Check the Optuna CSV log file \"\"\"\n",
        "pd.options.display.max_rows = 8 # limit rows to display\n",
        "print('Data Frame read from', ok.optuna_log_file_path, '\\n')\n",
        "display(pd.read_csv(ok.optuna_log_file_path))\n",
        "\n",
        "\"\"\" Check the Keras CSV log file \"\"\"\n",
        "pd.options.display.max_rows = 8 # limit rows to display\n",
        "print('Data Frame read from', ok.keras_log_file_path, '\\n')\n",
        "display(pd.read_csv(ok.keras_log_file_path))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best trial number:  26\n",
            "Best value: 0.9808000007629395\n",
            "Best parameters: \n",
            " {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "Best parameters (retrieved directly from Optuna) {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "Data Frame read from MNIST_Simple_Optuna.csv \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>state</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>activation</th>\n",
              "      <th>filters</th>\n",
              "      <th>kernel_size</th>\n",
              "      <th>strides</th>\n",
              "      <th>_Datetime_epoch_begin</th>\n",
              "      <th>_Datetime_epoch_end</th>\n",
              "      <th>_Trial_num</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>system_attrs__number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9734</td>\n",
              "      <td>2019-05-10 04:12:32.334166</td>\n",
              "      <td>2019-05-10 04:12:34.752164</td>\n",
              "      <td>relu</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:12:33.836179</td>\n",
              "      <td>2019-05-10 04:12:34.617735</td>\n",
              "      <td>0</td>\n",
              "      <td>0.960667</td>\n",
              "      <td>0.141006</td>\n",
              "      <td>0.9734</td>\n",
              "      <td>0.097551</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>2019-05-10 04:12:34.752439</td>\n",
              "      <td>2019-05-10 04:12:36.750894</td>\n",
              "      <td>linear</td>\n",
              "      <td>32</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:12:35.903388</td>\n",
              "      <td>2019-05-10 04:12:36.602301</td>\n",
              "      <td>1</td>\n",
              "      <td>0.917200</td>\n",
              "      <td>0.295365</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>0.284077</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9329</td>\n",
              "      <td>2019-05-10 04:12:36.751318</td>\n",
              "      <td>2019-05-10 04:12:38.439588</td>\n",
              "      <td>relu</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-05-10 04:12:37.760852</td>\n",
              "      <td>2019-05-10 04:12:38.291317</td>\n",
              "      <td>2</td>\n",
              "      <td>0.919717</td>\n",
              "      <td>0.283115</td>\n",
              "      <td>0.9329</td>\n",
              "      <td>0.239063</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9233</td>\n",
              "      <td>2019-05-10 04:12:38.440136</td>\n",
              "      <td>2019-05-10 04:12:40.549869</td>\n",
              "      <td>linear</td>\n",
              "      <td>32</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:12:39.657476</td>\n",
              "      <td>2019-05-10 04:12:40.394920</td>\n",
              "      <td>3</td>\n",
              "      <td>0.918917</td>\n",
              "      <td>0.287663</td>\n",
              "      <td>0.9233</td>\n",
              "      <td>0.269315</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9174</td>\n",
              "      <td>2019-05-10 04:15:22.803950</td>\n",
              "      <td>2019-05-10 04:15:24.625037</td>\n",
              "      <td>linear</td>\n",
              "      <td>64</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2019-05-10 04:15:23.902016</td>\n",
              "      <td>2019-05-10 04:15:24.469052</td>\n",
              "      <td>64</td>\n",
              "      <td>0.913367</td>\n",
              "      <td>0.301642</td>\n",
              "      <td>0.9174</td>\n",
              "      <td>0.285233</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9771</td>\n",
              "      <td>2019-05-10 04:15:24.632874</td>\n",
              "      <td>2019-05-10 04:15:27.765238</td>\n",
              "      <td>relu</td>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:15:26.400777</td>\n",
              "      <td>2019-05-10 04:15:27.608736</td>\n",
              "      <td>65</td>\n",
              "      <td>0.971317</td>\n",
              "      <td>0.102817</td>\n",
              "      <td>0.9771</td>\n",
              "      <td>0.077948</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>2019-05-10 04:15:27.772937</td>\n",
              "      <td>2019-05-10 04:15:30.909031</td>\n",
              "      <td>relu</td>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:15:29.531844</td>\n",
              "      <td>2019-05-10 04:15:30.750710</td>\n",
              "      <td>66</td>\n",
              "      <td>0.970183</td>\n",
              "      <td>0.106406</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>0.074906</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>TrialState.COMPLETE</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>2019-05-10 04:15:30.917168</td>\n",
              "      <td>2019-05-10 04:15:34.120557</td>\n",
              "      <td>relu</td>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:15:32.712900</td>\n",
              "      <td>2019-05-10 04:15:33.954044</td>\n",
              "      <td>67</td>\n",
              "      <td>0.970683</td>\n",
              "      <td>0.104216</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>0.073627</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    number                state   value              datetime_start  \\\n",
              "0        0  TrialState.COMPLETE  0.9734  2019-05-10 04:12:32.334166   \n",
              "1        1  TrialState.COMPLETE  0.9191  2019-05-10 04:12:34.752439   \n",
              "2        2  TrialState.COMPLETE  0.9329  2019-05-10 04:12:36.751318   \n",
              "3        3  TrialState.COMPLETE  0.9233  2019-05-10 04:12:38.440136   \n",
              "..     ...                  ...     ...                         ...   \n",
              "64      64  TrialState.COMPLETE  0.9174  2019-05-10 04:15:22.803950   \n",
              "65      65  TrialState.COMPLETE  0.9771  2019-05-10 04:15:24.632874   \n",
              "66      66  TrialState.COMPLETE  0.9778  2019-05-10 04:15:27.772937   \n",
              "67      67  TrialState.COMPLETE  0.9781  2019-05-10 04:15:30.917168   \n",
              "\n",
              "             datetime_complete activation  filters  kernel_size  strides  \\\n",
              "0   2019-05-10 04:12:34.752164       relu       32            5        1   \n",
              "1   2019-05-10 04:12:36.750894     linear       32            5        1   \n",
              "2   2019-05-10 04:12:38.439588       relu       32            3        2   \n",
              "3   2019-05-10 04:12:40.549869     linear       32            3        1   \n",
              "..                         ...        ...      ...          ...      ...   \n",
              "64  2019-05-10 04:15:24.625037     linear       64            3        2   \n",
              "65  2019-05-10 04:15:27.765238       relu       64            5        1   \n",
              "66  2019-05-10 04:15:30.909031       relu       64            5        1   \n",
              "67  2019-05-10 04:15:34.120557       relu       64            5        1   \n",
              "\n",
              "         _Datetime_epoch_begin         _Datetime_epoch_end  _Trial_num  \\\n",
              "0   2019-05-10 04:12:33.836179  2019-05-10 04:12:34.617735           0   \n",
              "1   2019-05-10 04:12:35.903388  2019-05-10 04:12:36.602301           1   \n",
              "2   2019-05-10 04:12:37.760852  2019-05-10 04:12:38.291317           2   \n",
              "3   2019-05-10 04:12:39.657476  2019-05-10 04:12:40.394920           3   \n",
              "..                         ...                         ...         ...   \n",
              "64  2019-05-10 04:15:23.902016  2019-05-10 04:15:24.469052          64   \n",
              "65  2019-05-10 04:15:26.400777  2019-05-10 04:15:27.608736          65   \n",
              "66  2019-05-10 04:15:29.531844  2019-05-10 04:15:30.750710          66   \n",
              "67  2019-05-10 04:15:32.712900  2019-05-10 04:15:33.954044          67   \n",
              "\n",
              "         acc      loss  val_acc  val_loss  system_attrs__number  \n",
              "0   0.960667  0.141006   0.9734  0.097551                     0  \n",
              "1   0.917200  0.295365   0.9191  0.284077                     1  \n",
              "2   0.919717  0.283115   0.9329  0.239063                     2  \n",
              "3   0.918917  0.287663   0.9233  0.269315                     3  \n",
              "..       ...       ...      ...       ...                   ...  \n",
              "64  0.913367  0.301642   0.9174  0.285233                    64  \n",
              "65  0.971317  0.102817   0.9771  0.077948                    65  \n",
              "66  0.970183  0.106406   0.9778  0.074906                    66  \n",
              "67  0.970683  0.104216   0.9781  0.073627                    67  \n",
              "\n",
              "[68 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Data Frame read from MNIST_Simple_Keras.csv \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>_Datetime_epoch_begin</th>\n",
              "      <th>_Datetime_epoch_end</th>\n",
              "      <th>_Trial_num</th>\n",
              "      <th>acc</th>\n",
              "      <th>loss</th>\n",
              "      <th>val_acc</th>\n",
              "      <th>val_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-05-10 04:12:32.812828</td>\n",
              "      <td>2019-05-10 04:12:33.785225</td>\n",
              "      <td>0</td>\n",
              "      <td>0.888283</td>\n",
              "      <td>0.414493</td>\n",
              "      <td>0.9481</td>\n",
              "      <td>0.183785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:12:33.836179</td>\n",
              "      <td>2019-05-10 04:12:34.617735</td>\n",
              "      <td>0</td>\n",
              "      <td>0.960667</td>\n",
              "      <td>0.141006</td>\n",
              "      <td>0.9734</td>\n",
              "      <td>0.097551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-05-10 04:12:35.023023</td>\n",
              "      <td>2019-05-10 04:12:35.859126</td>\n",
              "      <td>1</td>\n",
              "      <td>0.879000</td>\n",
              "      <td>0.434390</td>\n",
              "      <td>0.9170</td>\n",
              "      <td>0.292161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:12:35.903388</td>\n",
              "      <td>2019-05-10 04:12:36.602301</td>\n",
              "      <td>1</td>\n",
              "      <td>0.917200</td>\n",
              "      <td>0.295365</td>\n",
              "      <td>0.9191</td>\n",
              "      <td>0.284077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-05-10 04:15:28.084092</td>\n",
              "      <td>2019-05-10 04:15:29.480333</td>\n",
              "      <td>66</td>\n",
              "      <td>0.902067</td>\n",
              "      <td>0.355802</td>\n",
              "      <td>0.9623</td>\n",
              "      <td>0.136872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:15:29.531844</td>\n",
              "      <td>2019-05-10 04:15:30.750710</td>\n",
              "      <td>66</td>\n",
              "      <td>0.970183</td>\n",
              "      <td>0.106406</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>0.074906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>0</td>\n",
              "      <td>2019-05-10 04:15:31.242569</td>\n",
              "      <td>2019-05-10 04:15:32.654711</td>\n",
              "      <td>67</td>\n",
              "      <td>0.903500</td>\n",
              "      <td>0.352013</td>\n",
              "      <td>0.9632</td>\n",
              "      <td>0.132535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>1</td>\n",
              "      <td>2019-05-10 04:15:32.712900</td>\n",
              "      <td>2019-05-10 04:15:33.954044</td>\n",
              "      <td>67</td>\n",
              "      <td>0.970683</td>\n",
              "      <td>0.104216</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>0.073627</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>136 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     epoch       _Datetime_epoch_begin         _Datetime_epoch_end  \\\n",
              "0        0  2019-05-10 04:12:32.812828  2019-05-10 04:12:33.785225   \n",
              "1        1  2019-05-10 04:12:33.836179  2019-05-10 04:12:34.617735   \n",
              "2        0  2019-05-10 04:12:35.023023  2019-05-10 04:12:35.859126   \n",
              "3        1  2019-05-10 04:12:35.903388  2019-05-10 04:12:36.602301   \n",
              "..     ...                         ...                         ...   \n",
              "132      0  2019-05-10 04:15:28.084092  2019-05-10 04:15:29.480333   \n",
              "133      1  2019-05-10 04:15:29.531844  2019-05-10 04:15:30.750710   \n",
              "134      0  2019-05-10 04:15:31.242569  2019-05-10 04:15:32.654711   \n",
              "135      1  2019-05-10 04:15:32.712900  2019-05-10 04:15:33.954044   \n",
              "\n",
              "     _Trial_num       acc      loss  val_acc  val_loss  \n",
              "0             0  0.888283  0.414493   0.9481  0.183785  \n",
              "1             0  0.960667  0.141006   0.9734  0.097551  \n",
              "2             1  0.879000  0.434390   0.9170  0.292161  \n",
              "3             1  0.917200  0.295365   0.9191  0.284077  \n",
              "..          ...       ...       ...      ...       ...  \n",
              "132          66  0.902067  0.355802   0.9623  0.136872  \n",
              "133          66  0.970183  0.106406   0.9778  0.074906  \n",
              "134          67  0.903500  0.352013   0.9632  0.132535  \n",
              "135          67  0.970683  0.104216   0.9781  0.073627  \n",
              "\n",
              "[136 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdEzC5grp9ew",
        "colab_type": "text"
      },
      "source": [
        "## Optimization of a Keras model using more Optuna's features such as pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfV6iONwVujP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "771d3aff-8c66-4204-ab96-4b316e15ae11"
      },
      "source": [
        "study_name = dataset_name + '_Optimized'\n",
        "\n",
        "ok = OptKeras( \n",
        "    # parameters for optuna.create_study\n",
        "    storage='sqlite:///' + study_name + '_Optuna.db', \n",
        "    sampler=optuna.samplers.TPESampler(\n",
        "        consider_prior=True, prior_weight=1.0, \n",
        "        consider_magic_clip=True, consider_endpoints=False, \n",
        "        n_startup_trials=10, n_ei_candidates=24, \n",
        "        seed=None), \n",
        "    pruner=optuna.pruners.SuccessiveHalvingPruner(\n",
        "        min_resource=1, reduction_factor=4, min_early_stopping_rate=0), \n",
        "    study_name=study_name,\n",
        "    load_if_exists=True,\n",
        "    # parameters for OptKeras\n",
        "    monitor='val_acc',\n",
        "    direction='maximize',\n",
        "    enable_pruning=True, \n",
        "    models_to_keep=1, # Either 1, 0, or -1 (save all models) \n",
        "    verbose=1,\n",
        "    )\n",
        "\n",
        "def objective(trial): \n",
        "    epochs = 10\n",
        "    \n",
        "    K.clear_session()   \n",
        "    model = Sequential()\n",
        "    \n",
        "    if trial.suggest_int('Conv', 0, 1):  \n",
        "        # 1 Convolution layer\n",
        "        i = 1\n",
        "        model.add(Conv2D(\n",
        "            filters=int(trial.suggest_discrete_uniform(\n",
        "                'Conv_{}_num_filters'.format(i), 32, 64, 32)), \n",
        "            kernel_size=tuple([trial.suggest_int(\n",
        "                'Conv_{}_kernel_size'.format(i), 2, 3)] * 2),\n",
        "            activation='relu',\n",
        "            input_shape=input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=tuple([trial.suggest_int(\n",
        "                'Conv_{}_max_pooling_size'.format(i), 2, 3)] * 2)))\n",
        "        model.add(Dropout(trial.suggest_discrete_uniform(\n",
        "                'Conv_{}_dropout_rate'.format(i), 0, 0.5, 0.25) ))\n",
        "        model.add(Flatten())        \n",
        "    else:\n",
        "        model.add(Flatten(input_shape=input_shape))\n",
        "    # 2 Fully connected layers\n",
        "    for i in np.arange(2) + 1:\n",
        "        model.add(Dense(int(trial.suggest_discrete_uniform(\n",
        "            'FC_{}_num_hidden_units'.format(i), 256, 512, 256))))\n",
        "        if trial.suggest_int('FC_{}_batch_normalization'.format(i), 0, 1):\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(trial.suggest_categorical(\n",
        "            'FC_{}_acivation'.format(i), ['relu'])))\n",
        "        model.add(Dropout(\n",
        "            trial.suggest_discrete_uniform(\n",
        "                'FC_{}_dropout_rate'.format(i), 0, 0.5, 0.25) ))\n",
        "        \n",
        "    # Output layer    \n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    optimizer_dict = { \\\n",
        "    #'Adagrad': Adagrad(),\n",
        "    'Adam': Adam() }\n",
        "    \n",
        "    model.compile(optimizer = optimizer_dict[\n",
        "        trial.suggest_categorical('Optimizer', list(optimizer_dict.keys()))],\n",
        "          loss='sparse_categorical_crossentropy', metrics=['accuracy'])    \n",
        "    \n",
        "    if ok.verbose >= 2: model.summary()\n",
        "    \n",
        "    batch_size = trial.suggest_int('Batch_size', 256, 256) \n",
        "    data_augmentation = trial.suggest_int('Data_augmentation', 0, 1)\n",
        "    \n",
        "    if not data_augmentation:\n",
        "        # [Required] Specify callbacks(trial) in fit method\n",
        "        model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                  epochs=epochs, validation_data=(x_test, y_test),\n",
        "                  shuffle=True,\n",
        "                  callbacks=ok.callbacks(trial),\n",
        "                  verbose=ok.keras_verbose )\n",
        "    \n",
        "    if data_augmentation:\n",
        "        # This will do preprocessing and realtime data augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            width_shift_range=[-1, 0, +1], # 1 pixel\n",
        "            height_shift_range=[-1, 0, +1], # 1 pixel\n",
        "            zoom_range=[0.95,1.05],  # set range for random zoom\n",
        "            horizontal_flip=False,  # disable horizontal flip\n",
        "            vertical_flip=False )  # disable vertical flip\n",
        "        datagen.fit(x_train)\n",
        "        # [Required] Specify callbacks(trial) in fit_generator method\n",
        "        model.fit_generator(datagen.flow(x_train, y_train, \n",
        "                                         batch_size=batch_size),\n",
        "                            epochs=epochs, validation_data=(x_test, y_test),\n",
        "                            steps_per_epoch=len(x_train) // batch_size,\n",
        "                            callbacks=ok.callbacks(trial),\n",
        "                            verbose=ok.keras_verbose )\n",
        "    \n",
        "    # [Required] return trial_best_value (recommended) or latest_value\n",
        "    return ok.trial_best_value\n",
        "\n",
        "# Set n_trials and/or timeout (in sec) for optimization by Optuna\n",
        "ok.optimize(objective, timeout=3*60) # Run for 3 minutes for demo\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-05-10 04:15:34.581950] [OptKeras] Ready for optimization. (message printed as verbose is set to 1+)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "[2019-05-10 04:15:35.127617]  (None) \n",
            "[2019-05-10 04:17:20.868803] Trial#: 0, value: 9.848000e-01| Best trial#: 0, value: 9.848000e-01, params: {'Batch_size': 256, 'Conv': 0, 'Data_augmentation': 1, 'FC_1_acivation': 'relu', 'FC_1_batch_normalization': 0, 'FC_1_dropout_rate': 0.0, 'FC_1_num_hidden_units': 256.0, 'FC_2_acivation': 'relu', 'FC_2_batch_normalization': 0, 'FC_2_dropout_rate': 0.5, 'FC_2_num_hidden_units': 512.0, 'Optimizer': 'Adam'}\n",
            "[2019-05-10 04:17:51.646969] Trial#: 3, value: 9.886000e-01| Best trial#: 3, value: 9.886000e-01, params: {'Batch_size': 256, 'Conv': 1, 'Conv_1_dropout_rate': 0.25, 'Conv_1_kernel_size': 3, 'Conv_1_max_pooling_size': 2, 'Conv_1_num_filters': 32.0, 'Data_augmentation': 0, 'FC_1_acivation': 'relu', 'FC_1_batch_normalization': 0, 'FC_1_dropout_rate': 0.25, 'FC_1_num_hidden_units': 256.0, 'FC_2_acivation': 'relu', 'FC_2_batch_normalization': 0, 'FC_2_dropout_rate': 0.25, 'FC_2_num_hidden_units': 512.0, 'Optimizer': 'Adam'}\n",
            "[2019-05-10 04:19:42.183273] Trial#: 4, value: 9.925000e-01| Best trial#: 4, value: 9.925000e-01, params: {'Batch_size': 256, 'Conv': 1, 'Conv_1_dropout_rate': 0.0, 'Conv_1_kernel_size': 3, 'Conv_1_max_pooling_size': 3, 'Conv_1_num_filters': 64.0, 'Data_augmentation': 1, 'FC_1_acivation': 'relu', 'FC_1_batch_normalization': 0, 'FC_1_dropout_rate': 0.0, 'FC_1_num_hidden_units': 512.0, 'FC_2_acivation': 'relu', 'FC_2_batch_normalization': 0, 'FC_2_dropout_rate': 0.5, 'FC_2_num_hidden_units': 512.0, 'Optimizer': 'Adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xio3n-DJ7-F3",
        "colab_type": "text"
      },
      "source": [
        "## Randomized Grid Search of a simple Keras model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCarYfv175hC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "079897ba-aac6-4d21-a452-9c07e55903a1"
      },
      "source": [
        "study_name = dataset_name + '_GridSearch'\n",
        "\n",
        "\"\"\" To run randomized grid search, set random_grid_search_mode True \"\"\"\n",
        "ok = OptKeras(study_name=study_name, random_grid_search_mode=True)\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    K.clear_session()\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(\n",
        "        filters=trial.suggest_categorical('filters', [32, 64]),\n",
        "        kernel_size=trial.suggest_categorical('kernel_size', [3, 5]),\n",
        "        strides=trial.suggest_categorical('strides', [1]),\n",
        "        activation=trial.suggest_categorical('activation', ['relu', 'linear']),\n",
        "        input_shape=input_shape))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(x_train, y_train,\n",
        "              validation_data=(x_test, y_test), shuffle=True,\n",
        "              batch_size=512, epochs=2,\n",
        "              callbacks=ok.callbacks(trial),\n",
        "              verbose=ok.keras_verbose)\n",
        "\n",
        "    return ok.trial_best_value\n",
        "\n",
        "\"\"\" Set the number of parameter sets as n_trials for complete grid search \"\"\"\n",
        "ok.random_grid_search(objective, n_trials=2*2*2)  # 2*2*2 = 8 param sets\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2019-05-10 04:19:42.211378] [OptKeras] Ready for optimization. (message printed as verbose is set to 1+)\n",
            "[2019-05-10 04:19:42.303273]  (None) \n",
            "[2019-05-10 04:19:44.613135] Completed:  12% (    1 /     8)\n",
            "[2019-05-10 04:19:44.691397] Trial#: 0, value: 2.781258e-01| Best trial#: 0, value: 2.781258e-01, params: {'filters': 32, 'kernel_size': 3, 'strides': 1, 'activation': 'linear'}\n",
            "[2019-05-10 04:19:46.925172] Completed:  25% (    2 /     8)\n",
            "[2019-05-10 04:19:47.003790] Trial#: 1, value: 9.391315e-02| Best trial#: 1, value: 9.391315e-02, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:19:50.439585] Completed:  38% (    3 /     8)\n",
            "[2019-05-10 04:19:50.518369] Trial#: 2, value: 9.512007e-02| Best trial#: 1, value: 9.391315e-02, params: {'filters': 32, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:19:53.616758] Completed:  50% (    4 /     8)\n",
            "[2019-05-10 04:19:53.696223] Trial#: 3, value: 7.454754e-02| Best trial#: 3, value: 7.454754e-02, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:19:56.627346] Completed:  62% (    5 /     8)\n",
            "[2019-05-10 04:19:56.708482] Trial#: 4, value: 2.801971e-01| Best trial#: 3, value: 7.454754e-02, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:20:00.796777] Completed:  75% (    6 /     8)\n",
            "[2019-05-10 04:20:00.876683] Trial#: 6, value: 2.767171e-01| Best trial#: 3, value: 7.454754e-02, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:20:04.719995] Completed:  88% (    7 /     8)\n",
            "[2019-05-10 04:20:04.802376] Trial#: 8, value: 1.257678e-01| Best trial#: 3, value: 7.454754e-02, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n",
            "[2019-05-10 04:20:14.426849] Completed: 100% (    8 /     8)\n",
            "[2019-05-10 04:20:14.443835] Trial#: 13, value: 2.838137e-01| Best trial#: 3, value: 7.454754e-02, params: {'filters': 64, 'kernel_size': 5, 'strides': 1, 'activation': 'relu'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYKEKdiP6f6v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b5d4ca9-04ba-4478-9fe7-7c4aa2b546d1"
      },
      "source": [
        "\"\"\" ## The end of code. \"\"\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' ## The end of code. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Of83kdUpkmb",
        "colab_type": "text"
      },
      "source": [
        "Please feel free to post questions or feedback [here](\n",
        "https://github.com/Minyus/optkeras/issues\n",
        ")\n"
      ]
    }
  ]
}