{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OptKeras_Example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "adlTq181lzrT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook demonstrates how to use OptKeras, wrapper of Keras and Optuna"
      ]
    },
    {
      "metadata": {
        "id": "U087RvP2l0ew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Set up Google Colab environment\n",
        "\n",
        "To run in Google Colab, specify a directory in Google Drive. (GPU is recommended.)\n",
        "\n",
        "To run in an environment other than Google Colab, just skip this code."
      ]
    },
    {
      "metadata": {
        "id": "2M7KQx6HV40_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    import os\n",
        "    # Specify a directory in Google Drive\n",
        "    dir = '/content/drive/My Drive/Colab Notebooks/OptKeras'\n",
        "    os.chdir(dir)    \n",
        "    # Check the environment info\n",
        "    print('## Current working directory: ', os.getcwd())\n",
        "    print('## Check the uptime. (Google Colab reboots every 12 hours)')\n",
        "    !cat /proc/uptime | awk '{print \"Uptime is \" $1 /60 /60 \" hours (\" $1 \" sec)\"}'\n",
        "    print('## Check the GPU info')\n",
        "    !nvidia-smi\n",
        "    print('## Check the OS') \n",
        "    !cat /etc/issue\n",
        "    print('## Check the Python version') \n",
        "    !python --version\n",
        "    print('## Check the memory')\n",
        "    !free -h\n",
        "    print('## Check the disk')\n",
        "    !df -h\n",
        "except:\n",
        "    print('Run the code assuming the environment is not Google Colab.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "it4-DX10mqlB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install Optuna 0.7.0"
      ]
    },
    {
      "metadata": {
        "id": "XeNktIMgWNOg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install optuna==0.7.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COmhC_CuoYo9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install the latest version of OptKeras"
      ]
    },
    {
      "metadata": {
        "id": "zfIoE_CLvytu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Minyus/optkeras.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nikvt-fppC8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import modules"
      ]
    },
    {
      "metadata": {
        "id": "i85DbXl0nvmU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import Keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Flatten, Dense, Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, Adagrad, RMSprop, Adam, Adadelta, Adamax, Nadam\n",
        "import keras.backend as K\n",
        "\n",
        "import keras\n",
        "print('Keras', keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow', tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# import Optuna and OptKeras after Keras\n",
        "import optuna \n",
        "print('Optuna', optuna.__version__)\n",
        "\n",
        "from optkeras.optkeras import OptKeras\n",
        "import optkeras\n",
        "print('OptKeras', optkeras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mq16j0E4olJO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up Dataset"
      ]
    },
    {
      "metadata": {
        "id": "sfMZGHCO4DrV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset_name = 'MNIST'\n",
        "\n",
        "if dataset_name in ['MNIST', 'MNIST_1000samples']:\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    \n",
        "    img_x, img_y = x_train.shape[1], x_train.shape[2]\n",
        "    x_train = x_train.reshape(-1, img_x, img_y, 1)\n",
        "    x_test = x_test.reshape(-1, img_x, img_y, 1)   \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    num_classes = 10\n",
        "    input_shape = (img_x, img_y, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6QEQ_Dk6ReL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "17c48972-aa10-49ee-e12a-1d63dc21d301"
      },
      "cell_type": "code",
      "source": [
        "print('x_train: ', x_train.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('x_test: ', x_test.shape)\n",
        "print('y_test', y_test.shape)\n",
        "print('input_shape: ', input_shape )    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train:  (60000, 28, 28, 1)\n",
            "y_train (60000,)\n",
            "x_test:  (10000, 28, 28, 1)\n",
            "y_test (10000,)\n",
            "input_shape:  (28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Wb1ZX2vJDO1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Try a simple Convolutional Neural Networks model"
      ]
    },
    {
      "metadata": {
        "id": "m5NqIOlKJBpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d3c7b756-48ee-4d28-8eee-c53fc8fa851c"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, kernel_size = (3, 3), strides = (1, 1),\n",
        "               activation = 'relu', input_shape = input_shape))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(optimizer = Adam(), \n",
        "            loss='sparse_categorical_crossentropy', metrics=['accuracy'])\t\t\t  \n",
        "model.fit(x_train, y_train, validation_data = (x_test, y_test), shuffle = True,\n",
        "          batch_size = 512, epochs = 2) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.3370 - acc: 0.9098 - val_loss: 0.1314 - val_acc: 0.9622\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0988 - acc: 0.9728 - val_loss: 0.0789 - val_acc: 0.9766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f20e1ac4a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "JdEzC5grp9ew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a Keras model to optimize"
      ]
    },
    {
      "metadata": {
        "id": "LfV6iONwVujP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def objective(trial): \n",
        "    epochs = 10\n",
        "    \n",
        "    K.clear_session()   \n",
        "    model = Sequential()\n",
        "    \n",
        "    if trial.suggest_int('Conv', 0, 1):  \n",
        "        # 1 Convolution layer\n",
        "        i = 1\n",
        "        model.add(Conv2D(\n",
        "            filters = int(trial.suggest_discrete_uniform(\n",
        "                'Conv_{}_num_filters_'.format(i), 32, 64, 32)), \n",
        "            kernel_size=tuple([trial.suggest_int(\n",
        "                'Conv_{}_kernel_size'.format(i), 2, 3)] * 2),\n",
        "            activation='relu',\n",
        "            input_shape = input_shape))\n",
        "        model.add(MaxPooling2D(pool_size=tuple([trial.suggest_int(\n",
        "                'Conv_{}_max_pooling_size'.format(i), 2, 3)] * 2)))\n",
        "        model.add(Dropout(trial.suggest_discrete_uniform(\n",
        "                'Conv_{}_dropout_rate'.format(i), 0, 0.5, 0.25) ))\n",
        "        model.add(Flatten())        \n",
        "    else:\n",
        "        model.add(Flatten(input_shape=input_shape))\n",
        "    # 2 Fully connected layers\n",
        "    for i in np.arange(2) + 1:\n",
        "        model.add(Dense(int(trial.suggest_discrete_uniform(\n",
        "            'FC_{}_num_hidden_units'.format(i), 256, 512, 256))))\n",
        "        if trial.suggest_int('FC_{}_batch_normalization'.format(i), 0, 1):\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(Activation(trial.suggest_categorical(\n",
        "            'FC_{}_acivation'.format(i), ['relu'])))\n",
        "        model.add(Dropout(\n",
        "            trial.suggest_discrete_uniform(\n",
        "                'FC_{}_dropout_rate'.format(i), 0, 0.5, 0.25) ))\n",
        "        \n",
        "    # Output layer    \n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    optimizer_dict = { \\\n",
        "    #'Adagrad': Adagrad(),\n",
        "    'Adam': Adam() }\n",
        "    \n",
        "    model.compile(optimizer = optimizer_dict[\n",
        "        trial.suggest_categorical('Optimizer', list(optimizer_dict.keys()))],\n",
        "          loss='sparse_categorical_crossentropy', metrics=['accuracy'])    \n",
        "    \n",
        "    if ok.verbose >= 2: model.summary()\n",
        "    \n",
        "    batch_size = trial.suggest_int('Batch_size', 256, 256) \n",
        "    #batch_size = int(trial.suggest_discrete_uniform(\n",
        "    #                  'Batch_size', 256, 512, 256) )\n",
        "    data_augmentation = trial.suggest_int('Data_augmentation', 0, 1)\n",
        "    \n",
        "    if not data_augmentation:\n",
        "        # [Required] Specify callbacks(trial) in fit method\n",
        "        model.fit(x_train, y_train, batch_size = batch_size,\n",
        "                  epochs = epochs, validation_data = (x_test, y_test),\n",
        "                  shuffle = True,\n",
        "                  callbacks = ok.callbacks(trial), \n",
        "                  verbose = ok.keras_verbose )\n",
        "    \n",
        "    if data_augmentation:\n",
        "        # This will do preprocessing and realtime data augmentation:\n",
        "        datagen = ImageDataGenerator(\n",
        "            width_shift_range=[-1, 0, +1], # 1 pixel\n",
        "            height_shift_range=[-1, 0, +1], # 1 pixel\n",
        "            zoom_range=[0.95,1.05],  # set range for random zoom\n",
        "            horizontal_flip=False,  # disable horizontal flip\n",
        "            vertical_flip=False )  # disable vertical flip\n",
        "        datagen.fit(x_train)\n",
        "        # [Required] Specify callbacks(trial) in fit_generator method\n",
        "        model.fit_generator(datagen.flow(x_train, y_train, \n",
        "                                         batch_size=batch_size),\n",
        "                            epochs=epochs, validation_data=(x_test, y_test),\n",
        "                            steps_per_epoch=len(x_train) // batch_size,\n",
        "                            callbacks = ok.callbacks(trial), \n",
        "                            verbose = ok.keras_verbose )  \n",
        "    \n",
        "    # [Required] return trial_best_value (recommended) or latest_value\n",
        "    return ok.trial_best_value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUrj6NZWqB8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Run optimization trials"
      ]
    },
    {
      "metadata": {
        "id": "GCkV2XqeBMhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "study_name = dataset_name + '_Optimized'\n",
        "\n",
        "ok = OptKeras( \n",
        "    ## parameters for optuna.create_study\n",
        "    storage='sqlite:///' + study_name + '_Optuna.db', \n",
        "    sampler=None, \n",
        "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=0), \n",
        "    study_name = study_name, \n",
        "    direction='minimize', \n",
        "    load_if_exists = True,\n",
        "    ## parameters for OptKeras\n",
        "    monitor = 'val_error', # Either 'val_error' (1 - val_acc) or 'val_loss'\n",
        "    enable_pruning = False, \n",
        "    num_models_to_save = 1, # Either 1, 0, or -1 (save all models) \n",
        "    verbose = 1 )\n",
        "\n",
        "# Set n_trials and/or timeout (in sec) for optimization by Optuna\n",
        "ok.optimize(objective, n_trials=10, timeout = 12 * 60 * 60)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auoF6dt0sWCl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check the results"
      ]
    },
    {
      "metadata": {
        "id": "6y5SKUF9qXlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "151938a3-45e0-4c1f-efca-37a2c58f4f96"
      },
      "cell_type": "code",
      "source": [
        "# OptKeras best_trial returns \n",
        "print('Best trial id: ', ok.best_trial.trial_id)\n",
        "print('Best value:', ok.best_trial.value)\n",
        "print('Best params: ')\n",
        "ok.best_trial.params"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best trial id:  8\n",
            "Best value: 0.008600000000000052\n",
            "Best params: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Batch_size': 256,\n",
              " 'Conv': 1,\n",
              " 'Conv_1_dropout_rate': 0.5,\n",
              " 'Conv_1_kernel_size': 3,\n",
              " 'Conv_1_max_pooling_size': 3,\n",
              " 'Conv_1_num_filters_': 32.0,\n",
              " 'Data_augmentation': 0,\n",
              " 'FC_1_acivation': 'relu',\n",
              " 'FC_1_batch_normalization': 1,\n",
              " 'FC_1_dropout_rate': 0.0,\n",
              " 'FC_1_num_hidden_units': 256.0,\n",
              " 'FC_2_acivation': 'relu',\n",
              " 'FC_2_batch_normalization': 1,\n",
              " 'FC_2_dropout_rate': 0.5,\n",
              " 'FC_2_num_hidden_units': 512.0,\n",
              " 'Optimizer': 'Adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "_3VjUGT7AVqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Alternatively, you can access Optuna's study object to, for example, \n",
        "get the best parameters as well.\n",
        "Please note that study.best_trial returns error if optimization trials \n",
        "were not completed (e.g. if you interupt execution) as of Optuna 0.7.0, \n",
        "so usage of OptKeras is recommended.\n",
        "\"\"\"\n",
        "study = ok.study\n",
        "study.best_trial.params "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTGnnvpDF5IE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Check the Optuna CSV log file \n",
        "pd.options.display.max_rows = 8 # limit rows to display\n",
        "print('Data Frame read from', ok.optuna_log_file_path, '\\n')\n",
        "pd.read_csv(ok.optuna_log_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aECKs3b8bR6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Check the Keras CSV log file\n",
        "\n",
        "pd.options.display.max_rows = 8 # limit rows to display\n",
        "print('Data Frame read from', ok.keras_log_file_path, '\\n')\n",
        "pd.read_csv(ok.keras_log_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}